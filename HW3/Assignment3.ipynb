{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Platform\n",
    "## Assignment 3: ServerLess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By:**  \n",
    "\n",
    "Or Livne, 300123123  \n",
    "Roy Rubin, 201312907\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal of this assignment is to:**\n",
    "- Understand and practice the details of Serverless\n",
    "\n",
    "**Instructions:**\n",
    "- Students will form teams of two people each, and submit a single homework for each team.\n",
    "- The same score for the homework will be given to each member of your team.\n",
    "- Your solution is in the form of a Jupyter notebook file (with extension ipynb).\n",
    "- Images/Graphs/Tables should be submitted inside the notebook.\n",
    "- The notebook should be runnable and properly documented. \n",
    "- Please answer all the questions and include all your code.\n",
    "- You are expected to submit a clear and pythonic code.\n",
    "- You can change functions signatures/definitions.\n",
    "\n",
    "**Submission:**\n",
    "- Submission of the homework will be done via Moodle by uploading (not Zip):\n",
    "    - Jupyter Notebook\n",
    "    - 2 Log files\n",
    "    - Additional local scripts\n",
    "- The homework needs to be entirely in English.\n",
    "- The deadline for submission is on Moodle.\n",
    "- Late submission won't be allowed.\n",
    "\n",
    "  \n",
    "- In case of identical code submissions - both groups will get a Zero. \n",
    "- Some groups might be selected randomly to present their code.\n",
    "\n",
    "**Requirements:**  \n",
    "- Python 3.6 should be used.  \n",
    "- You should implement the algorithms by yourself using only basic Python libraries (such as numpy,pandas,etc.)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grading:**\n",
    "- Q0 - 10 points - Setup\n",
    "- Q1 - 40 points - Serverless MapReduceEngine\n",
    "- Q2 - 20 points - MapReduce job to calculate inverted index\n",
    "- Q3 - 30 points - Shuffle\n",
    "\n",
    "`Total: 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0\n",
    "## Setup\n",
    "\n",
    "1. Navigate to IBM Cloud and open a trial account. No need to provide a credit card\n",
    "2. Choose IBM Cloud Object Storage service from the catalog\n",
    "3. Create a new bucket in IBM Cloud Object Storage\n",
    "4. Create credentials for the bucket with HMAC (access key and secret key)\n",
    "5. Choose IBM Cloud Functions service from the catalog and create a service\n",
    "\n",
    "\n",
    "#### Lithops setup\n",
    "1. By using “git” tool, install master branch of the Lithops project from\n",
    "https://github.com/lithops-cloud/lithops\n",
    "2. Follow Lithops documentation and configure Lithops against IBM Cloud Functions and IBM Cloud Object Storage\n",
    "3. Configure Lithops log level to be in DEBUG mode\n",
    "4. Run Hello World example by using Futures API and verify all is working properly.\n",
    "\n",
    "\n",
    "#### IBM Cloud Object Storage setup\n",
    "1. Upload all the input CSV files that you used in homework 2 into the bucket you created in IBM Cloud Object Storage\n",
    "\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "## Serverless MapReduceEngine\n",
    "\n",
    "Modify MapReduceEngine from homework 2 into the MapReduceServerlessEngine where map and reduce tasks executed as a serverless actions, instead of local threads. In particular:\n",
    "1. Deploy all map tasks as a serverless actions by using Lithops against IBM Cloud Functions.\n",
    "2. Collect results from all map tasks and store them in the same SQLite as you used in MapReduceEngine and use the same code for the sort and shuffle phase.\n",
    "3. Deploy reduce tasks by using Lithops against IBM Cloud Functions. Instead of persisting results from reduce tasks, return results back to the MapReduceServerlessEngine and proceed with the same workflow as in MapReduceEngine\n",
    "4. Return results of reduce tasks to the user\n",
    "\n",
    "**Please attach:**  \n",
    "Text file with all log messages Lithops printed to console during the execution. Make\n",
    "sure log level is set to DEBUG mode.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "import lithops\n",
    "from lithops import Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set our IBM configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "for HW checker - if you wish to use your own connector, please change config accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = {\n",
    "    'lithops': \n",
    "        {\n",
    "        'backend': 'ibm_cf',\n",
    "        'storage': 'ibm_cos',\n",
    "        # 'log_level': 'DEBUG'  # Log files included seperatly. uncomment if needed.\n",
    "        },\n",
    "    'ibm_cf': \n",
    "        {\n",
    "        'endpoint': 'https://us-south.functions.cloud.ibm.com',\n",
    "        'namespace': 'roy.rubin@post.idc.ac.il_dev',\n",
    "        'api_key': '1defbac0-eea1-4bb8-b5d4-cee7e63b3bb4:63a0ls32DAGjVe0TkdUcBqcOL7lOtR7bLsQYf98WGgW2xpp9Bpd0BUSubnlsfNQM',\n",
    "        # 'runtime': '3.7',\n",
    "        },\n",
    "    'ibm_cos': \n",
    "        {\n",
    "        'storage_bucket': 'cloud-object-storage-mq-cos-standard-8s4',\n",
    "        'region': 'eu-de',\n",
    "        \"access_key\": \"bb21b4d35ef046d19b4f6fd93f39a3a5\",\n",
    "        \"secret_key\": \"d9db9b67564ec2fc5467820ef8719533cdc2e64a5ce33695\",\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_configurations():\n",
    "    # Set the value options\n",
    "    global max_rows, csv_columns, db_file_name, csv_file_name, columns_type\n",
    "    global csv_index, csv_ending, amount_of_files\n",
    "    global map_reduce_folder_names, amount_of_process, map_regex, db_columns\n",
    "    global db_columns_type, db_table_name, reduce_regex_init, reduce_regex_final\n",
    "\n",
    "    Current_python_file_path = os.getcwd()\n",
    "    max_rows = 10\n",
    "    amount_of_files = 20\n",
    "    csv_columns = ['firstname', 'secondname', 'city']\n",
    "    csv_file_name = 'myCSV'\n",
    "    csv_ending = '.csv'\n",
    "    \n",
    "    # db_definitions\n",
    "    db_columns = ['key', 'value']\n",
    "    db_columns_type = ['text', 'text']\n",
    "    db_file_name = 'mydata.db'\n",
    "    db_table_name = 'temp_results'\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our map and reduce functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_map(document_name: str):\n",
    "    try:\n",
    "        # Preparations\n",
    "        storage = Storage(config=global_config)\n",
    "        data = storage.get_object(global_config['ibm_cos']['storage_bucket'], document_name)\n",
    "\n",
    "        # Begin\n",
    "        csv_df = pd.read_csv(BytesIO(data), encoding='utf8', sep=\",\", index_col=0)\n",
    "        csv_size = csv_df.shape[0]\n",
    "        csv_columns = csv_df.columns.to_list()\n",
    "        output_list = []\n",
    "        for i_col in csv_columns:\n",
    "            col_vals = csv_df[i_col].to_list()\n",
    "            curr_ouput = list(map(lambda x, y, z: (x + '_' + y, z), csv_size * [i_col], col_vals, csv_size * [document_name]))\n",
    "            output_list += curr_ouput\n",
    "\n",
    "    except Exception as exception:\n",
    "        return [], False\n",
    "\n",
    "    return output_list, True\n",
    "\n",
    "\n",
    "def inverted_reduce(data):\n",
    "    try:\n",
    "        value, documents = data\n",
    "        ducument_name_list = documents.split(',')\n",
    "        ducument_name_list_no_duplicates = list(set(ducument_name_list))\n",
    "        string_ducument_name_list_no_duplicates = (', ').join(ducument_name_list_no_duplicates)\n",
    "        return_list = [value, string_ducument_name_list_no_duplicates]\n",
    "\n",
    "    except Exception as exception:\n",
    "        return [], False\n",
    "\n",
    "    return return_list, True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serverless Map Reduce Engine !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapReduceServerlessEngine(object):\n",
    "    def __init__(self):\n",
    "        # create a function executor\n",
    "        self._fexec = lithops.FunctionExecutor(config=global_config)\n",
    "        self._bucket_name = global_config['ibm_cos']['storage_bucket']\n",
    "        self._region_name = global_config['ibm_cos']['region']\n",
    "        self._create_database()\n",
    "\n",
    "    def execute(self, input_data, map_function, reduce_function):\n",
    "        \"\"\"\n",
    "        execute map and reduce\n",
    "\n",
    "        :param input_data: assumption: given as:     input_data = 'cos://bucket/<path to CSV data>'\n",
    "        :param map_function:\n",
    "        :param reduce_function:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #  1) For each key  from the  input_data, start a new Python thread that executes\n",
    "        #     map_function(key)\n",
    "        #  2) Each serverless action will store results of the map_function into\n",
    "        #     mapreducetemp/part-tmp-X.csv where X\n",
    "        #     is a unique number per each thread.\n",
    "        #  3) Keep the list of all threads and check whether they are completed\n",
    "\n",
    "        # Create cloud storage object\n",
    "        self._storage = Storage(config=global_config)\n",
    "        _, _, path_to_csv = self._parse_input_data(input_data)\n",
    "\n",
    "        list_of_objects = self._storage.list_objects(bucket=self._bucket_name, prefix=path_to_csv)\n",
    "        list_of_csv_objects = [item for item in list_of_objects if '.csv' in item['Key']]\n",
    "        list_of_csv_names = [item['Key'] for item in list_of_csv_objects if '.csv' in item['Key']]\n",
    "\n",
    "        # call function async-ly\n",
    "        response_list = []\n",
    "        for csv_name in list_of_csv_names:\n",
    "            response = self._fexec.call_async(func=map_function, data={'document_name': csv_name})\n",
    "            response_list.append(response)\n",
    "\n",
    "        try:\n",
    "            results = self._fexec.get_result(fs=response_list)  # internally calls wait. note: if one fails, all fails !\n",
    "            self._fexec.clean()\n",
    "        except Exception as exception:\n",
    "            status = 'Map Reduce Failed'\n",
    "            return status\n",
    "\n",
    "        # get all map logs\n",
    "        map_loglist = list(map(lambda x: x.logs, response_list))\n",
    "        \n",
    "        # get list of succeed or failed of threads\n",
    "        boolean_results = [boolean for output, boolean in results]\n",
    "\n",
    "        # validate that all threads are completed succesfully\n",
    "        if False in boolean_results:\n",
    "            status = 'Map Reduce Failed'\n",
    "            return status\n",
    "\n",
    "        # 4) Once all threads completed, load content of all CSV files into the temp_results\n",
    "        #    table in SQLite\n",
    "\n",
    "        # get new files names\n",
    "        outputs = [output for output, boolean in results]\n",
    "\n",
    "        # write generated csv files to sql data base\n",
    "        sql_conn = sqlite3.connect(db_file_name)\n",
    "        for output in outputs:\n",
    "            result_df = pd.DataFrame(data=output, columns=['key', 'value'])\n",
    "            result_df.to_sql('temp_results', sql_conn, if_exists='append', index=False)\n",
    "\n",
    "        # dont forget to close connection after finishing\n",
    "        sql_conn.close()\n",
    "\n",
    "        # 5) **Write SQL statement** that generates a sorted list by key of the form\n",
    "        #    `(key, value)` where value is concatenation of ALL values in the value column\n",
    "        #     that match specific key. For example, if table has records\n",
    "\n",
    "        # query data base using GROUP_CONCAT and GROUP BY  and ORDER BY\n",
    "        generated_list = self._get_grouped_info_from_db_by_key(key='key')\n",
    "\n",
    "        # 6) **Start a new serverless execution** for each value from\n",
    "        #    the generated list in the previous step, to execute `reduce_function(key,value)\n",
    "        #    Begin by Performing REDUCE actions\n",
    "        #    we will open a thread for each REDUCE\n",
    "        # 7) Each thread will store results of reduce_function into\n",
    "        #   `mapreducefinal/part-X-final.csv` file\n",
    "\n",
    "        # 8) Keep list of all threads and check whether they are completed\n",
    "\n",
    "        # call function async-ly\n",
    "        response_list = []\n",
    "        for item in generated_list:\n",
    "            response = self._fexec.call_async(func=reduce_function, data={'data': item})\n",
    "            response_list.append(response)\n",
    "\n",
    "        try:\n",
    "            results = self._fexec.get_result(fs=response_list)  # internally calls wait. note: if one fails, all fails !\n",
    "            self._fexec.clean()\n",
    "        except Exception as exception:\n",
    "            status = 'Map Reduce Failed'\n",
    "            return status\n",
    "\n",
    "        # 9) Once all threads completed, print on the screen\n",
    "        #   `MapReduce Completed` otherwise print `MapReduce Failed`\n",
    "        \n",
    "        # get all reduce logs\n",
    "        reduce_loglist = list(map(lambda x: x.logs, response_list))\n",
    "\n",
    "        # get list of succeed or failed of threads\n",
    "        boolean_results = [boolean for output, boolean in results]\n",
    "\n",
    "        # validate that all threads are completed succesfully\n",
    "        if False in boolean_results:\n",
    "            status = 'Map Reduce Failed'\n",
    "            return status\n",
    "\n",
    "        # write all serverless execution logs (for each \"response\" object) to file\n",
    "        log_seprator = '----------------------------------'\n",
    "        map_and_reduce_logs = [log_seprator+ 'Map log' + log_seprator] + map_loglist + reduce_loglist + [log_seprator+'Reduce log' +log_seprator]\n",
    "        write_list_to_txt_file('future_responses_logs_file.txt', map_and_reduce_logs)\n",
    "\n",
    "        # return map+reduce output as pandas dataframe for user\n",
    "        outputs = [output for output, boolean in results]\n",
    "        reduce_df = pd.DataFrame(data=outputs)\n",
    "        return reduce_df\n",
    "\n",
    "\n",
    "    def _get_grouped_info_from_db_by_key(self, key):\n",
    "        con = sqlite3.connect(db_file_name)\n",
    "        cur = con.cursor()\n",
    "        return_list = []\n",
    "        for row in cur.execute(\n",
    "                'SELECT key, GROUP_CONCAT(value) FROM ' + db_table_name + ' GROUP BY ' + key + ' ORDER BY ' + key):\n",
    "            # print(row)\n",
    "            return_list.append(row)\n",
    "        con.close()\n",
    "        return return_list\n",
    "\n",
    "    def _parse_input_data(self, input_data: str):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_data: assumption: format is something like :  input_data = 'cos://eu-de/cloud-object-storage-mq-cos-standard-8s4/myCSV0.csv'\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if input_data is None or input_data == '':\n",
    "            raise AssertionError(f'Bad arguments passed: input_data is None or input_data == ''')\n",
    "\n",
    "        sep = '/'\n",
    "        parts = input_data.split(sep='cos://')[1].split(sep=sep)\n",
    "\n",
    "        region = parts[0]\n",
    "        bucket = parts[1]\n",
    "        path_to_csv = sep + sep.join(parts[2:])\n",
    "\n",
    "        if self._bucket_name != bucket:\n",
    "            raise AssertionError(f'bucket name in input data does not match the one given in global config')\n",
    "        if self._region_name != region:\n",
    "            raise AssertionError(f'region name in input data does not match the one given in global config')\n",
    "\n",
    "        return region, bucket, path_to_csv\n",
    "\n",
    "    def _create_database(self):\n",
    "        is_exist = os.path.exists(db_file_name)\n",
    "        if is_exist:\n",
    "            os.remove(db_file_name)\n",
    "        con = sqlite3.connect(db_file_name)\n",
    "\n",
    "        cur = con.cursor()\n",
    "\n",
    "        # Create table\n",
    "        columns_type_list = list(map(lambda x, y: x + ' ' + y, db_columns, db_columns_type))\n",
    "        columns_type_list_string = \"(\" + \", \".join(map(str, columns_type_list)) + \")\"\n",
    "\n",
    "        cur.execute(''' \n",
    "                    CREATE TABLE temp_results\n",
    "                    ''' + columns_type_list_string + \\\n",
    "                    '''''')\n",
    "\n",
    "        con.commit()\n",
    "        con.close()\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assisting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_txt_file(path, List):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in List:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Submit MapReduce job to calculate inverted index\n",
    "1. Use input_data: `cos://bucket/<path to CSV data>`\n",
    "2. Submit MapReduce job with reduce and map functions as you used in homework 2, as follows\n",
    "\n",
    "    `mapreduce = MapReduceServerlessEngine()`  \n",
    "    `results = mapreduce.execute(input_data, inverted_map, inverted_index)`   \n",
    "    `print(results)`\n",
    "\n",
    "**Please attach:**  \n",
    "Text file with all log messages Lithops printed to console during the execution. Make\n",
    "sure log level is set to DEBUG mode.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data:\n",
      "cos://eu-de/cloud-object-storage-mq-cos-standard-8s4/HW3Data/CSVData/\n"
     ]
    }
   ],
   "source": [
    "# Prepare global configs\n",
    "init_configurations()\n",
    "\n",
    "# Prepare inout_data\n",
    "separator = '/'\n",
    "ibm_intro = 'cos://'\n",
    "path_to_csv = 'HW3Data/CSVData/'\n",
    "input_data = ibm_intro + global_config['ibm_cos']['region'] + separator + global_config['ibm_cos']['storage_bucket'] + separator + path_to_csv\n",
    "print(f'input_data:\\n{input_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "mapreduce = MapReduceServerlessEngine()\n",
    "result = mapreduce.execute(input_data, inverted_map, inverted_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "if os.path.exists(db_file_name):\n",
    "    os.remove(db_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print results as data frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "## Shuffle\n",
    "\n",
    "MapReduceServerlessEngine deploys both map and reduce tasks as serverless invocations.   \n",
    "However, once map stage completed, the result are transferred from the map tasks to the SQLite database located on the client machine (laptop in your case), then performed local shuffle and then invoked reduce tasks passing them relevant parameters.\n",
    "\n",
    "(To support your answers, feel free to use examples, Images, etc.)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Explain why this approach is not efficient and what are cons and pros of such architecture in general. In broader scope you may assume that MapReduceServerlessEngine executed in some powerful machine and not just laptop.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serverless approach benfits and drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\n",
    "\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the lectures & images presented above:\n",
    "\n",
    "* Reasons this approach is not efficient:\n",
    "    * Time consuming - the data is being transferred from local computer to the cloud and back, each transfer of data takes time\n",
    "    * Security issues - because of the data transfering between local and cloud machines mentioned above  we are exposed to data\\knowledge leakage (cyber attacks) \n",
    "    * Debug abilities - in a local computer we can fully debug our code, however we cannot access all information from cloud actions, and cannot fully debug it there.\n",
    "    \n",
    "* Reasons this approach is efficient because:\n",
    "    * Cost efficient - cloud usage is costly, and so if there are any actions we can do localy, we can save more money. \n",
    "    * Debug abilities - in a local computer we can fully debug our code.\n",
    "    * Computation Resources - Relative to the map and reduce actions, the shuffle action might be lighter (in terms of required computation power) and so we can save also our serverless computing power for more complex actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**2. Suggest how can you improve shuffle so intermediate data will not be downloaded to the client at all and shuffle performed in the cloud as well. Explain pros and cons of the approaches you suggest.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can improve shuffle so it will be performed in the cloud and intermediate data will not be downloaded to the client by:\n",
    "    * running map --> shuffle --> reduce on the cloud each as a serverless action (or multiple ones) while persisting temp results in cloud storage\n",
    "    * running map --> shuffle --> reduce on the cloud each as a serverless action (or multiple ones) while map results are passed straight to the shuffle action, and it will then be passed on straight to the reduce actions\n",
    "\n",
    "* pro for shuffling on cloud \n",
    "    * Computation Resources: this approach frees up client computation resources.\n",
    "    * Ease usage: with this approach there is no need to parse cloud results, only get final results.\n",
    "* cons for shuffling on cloud \n",
    "    * Debug Abilities: it might be difficult to debug the shuffle steps in the cloud\n",
    "    * Computation Utilization: cloud machines are usually strong devices that can be scaled easily. since the shuffling operation might be a relatively simple task, it would be a waste to use our strong resources for it.\n",
    "    * Cloud traffic: since we are not the only users on the cloud machines, the machines might be accepting multiple requests, which might mean our job will take longer to run.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**3. Can you make serverless shuffle?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* serverless actions can perform any task, and specifically as mentioned above we believe that we can do shuffle steps with these serverlessserverless.\n",
    "* please see our answers above for pros and cons for this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "Good Luck :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
